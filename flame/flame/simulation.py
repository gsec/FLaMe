#!/usr/bin/env python2
# encoding: utf-8
"""
Define the general structure of the simulations. We will create a hierarchy in the HDF
data format and group those elements into [simulation] > [TP state] > [samples]. A sample
is the smallest unit, a flake generated by the `growth` module.
"""

from __future__ import print_function, division, generators
import logging
import yaml
import sys
import tables as tb
from os import getcwd, path
from random import random
from flame.growth import Flake
from flame.settings import PARAMS_YAML, get_time, get_skel

logger = logging.getLogger(__name__)


class Stage(tb.IsDescription):
    """ Definition class for output of `geometry()` at a snapshot.

    The most interesting here are the `aspect_ratio` as we want to maximize this through
    the twin plane configuration. As well as `height` or `layers` for vertical size and
    `iter` indicating how many atoms have been grown. We want to average those and plot
    the height against the iterations, indicating the growth time.
    """
    radius          = tb.Float32Col()
    height          = tb.Float32Col()
    aspect_ratio    = tb.Float32Col()
    area            = tb.Float32Col()
    layers          = tb.Int32Col()
    iter            = tb.Int32Col()


def run(name, params):
    """ Spawn HDF file and create basic structure for the experiment.

    The `identifier` is composed from the name and a random hash value to
    differentiate different runs of the same simulation.


    * create an unique identifier value
    * create a mapping through lambda evaluation
    * generate twin plane configuration for each value
      and match the string in the description
    """
    while True:             # ensure that the id is unique
        identifier = str(name) + '_' + hex(hash(random()))
        fname = identifier + '.hdf'
        if not path.isfile(fname):
            break

    logger.info('\t STARTED >>> {}\n'.format(identifier))
    for k, v in params.items():
        logger.info('{}: {}'.format(k, v))

    mapping = eval('lambda x:' + params['function'])        # Care, eval is evil

    with tb.open_file(fname, mode='w', title='Test file') as h5file:
        for each_value in params['values']:
            twinplane_set = tuple(set(mapping(each_value)))
            twinplane_string = '/twins_{}'.format(      # convert minus sign to zero char
                '_'.join('0' + str(abs(tp)) if tp < 0 else str(tp) for tp in
                         sorted(list(twinplane_set))))

            logger.info(' @{time} Twinplanes {twins} Total Size: {size}'.format(
                time=' :: '.join(get_time()),
                twins=twinplane_set,
                size=params['total_size']))

            for sample in range(params['sample_size']):
                table = h5file.create_table(
                    twinplane_string, 'flake{:03}'.format(sample), Stage, 'FlakeSample',
                    createparents=True)
                logger.info('Sampling... {}/{}'.format(
                    sample + 1, params['sample_size']))

                snapshot = table.row
                flake_gen = builder(twinplane_set, **params)

                for stage in flake_gen:
                    for k, v in stage.items():
                        snapshot[k] = v
                    snapshot.append()
                table.flush()
    logger.info('SIMULATION ENDED >>> {}'.format(identifier))


def store_hashed_params():
    #TODO: put attributes into hdf, ensure sim_params.yaml is not altered afterwards.
    pass


def read_params():
    """ Ensures the parameters are read in from a YAML file.

    A simulation is defined through its configuration file. Here we use YAML
    since it is human- and machine-readable.
    """
    def get_config():
        try:
            with open(PARAMS_YAML, 'r') as file_handler:
                params = yaml.load(file_handler)
            return params
        except IOError:
            sys.exit("'{}' must be created before running a simulation. "
                     "Try the `create` command.".format(PARAMS_YAML))

    params = get_config()
    name = getcwd().split('/')[-1]
    return name, params


def builder(tp, total_size=10000, snapshot_interval=1000, **kwargs):
    """ Create generator that yields the geometry of growing Flake.

    Generate a `Flake` instance from the `growth` module. By consuming an item we grow
    the flake by the amount in `snapshot_interval` and yield the output of our
    `geometry` method.
    """
    try:
        xargs = kwargs['flake']
    except KeyError:
        xargs = {'': None}

    thisFlake = Flake(*tp, **xargs)

    while thisFlake.iter < total_size:
        thisFlake.grow(snapshot_interval)
        yield thisFlake.geometry()


def create(project_name):
    """ Create a default YAML file for the project.

    Optional argument: @name   :: If not provided, naming defaults to directory name.
    """
    if path.isfile(PARAMS_YAML):
        sys.exit("Parameters file already exists in {}\n".format(getcwd()) +
                 "Please create each simulation in a separate folder.")

    output = get_skel(project_name)

    with open(PARAMS_YAML, 'w') as handler:
        handler.write(output)
    logger.info('Parameter file written to {}'.format(PARAMS_YAML))
